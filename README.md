# Distilling Efficient Vision Transformers from CNNs for Segmentation: A Vision-Language Perspective

![C2VKD_cover](https://user-images.githubusercontent.com/49426295/208649286-b3f08a0e-5444-447e-9c03-d638aaa9380a.jpg)

This repository contains the source code of **C2VKD** from the paper [Distilling Efficient Vision Transformers from CNNs for Segmentation: A Vision-Language Perspective]().

In this paper, we tackle a new problem: how to transfer knowledge from the pretrained cumbersome yet high-performance CNN-based model to learn a compact Vision transformer (ViT)-based model while maintaining its learning capacity?
